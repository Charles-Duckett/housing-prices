{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from geopy.distance import geodesic\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('housing.csv')\n",
    "cal_cities = pd.read_csv('cal_cities_lat_long.csv')\n",
    "cal_pops_cities = pd.read_csv('cal_populations_city.csv')\n",
    "cal_pops_counties = pd.read_csv('cal_populations_county.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('median_house_value', axis=1)\n",
    "y = df['median_house_value']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[X_train['ocean_proximity'] == '<1H OCEAN', 'ocean_proximity'] = 'WITHIN HOUR TO OCEAN'\n",
    "X_train['total_bedrooms'].fillna(X_train['total_bedrooms'].median(), inplace=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['rooms_per_household'] = X_train['total_rooms'] / X_train['households']\n",
    "X_train['bedrooms_per_room'] = X_train['total_bedrooms'] / X_train['total_rooms']\n",
    "X_train['population_per_household'] = X_train['population'] / X_train['households']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['total_rooms'], axis=1, inplace=True)\n",
    "X_train.drop(['total_bedrooms'], axis=1, inplace=True)\n",
    "X_train.drop(['households'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join('CA_Counties', 'CA_Counties_TIGER2016.shp')\n",
    "cali_shp = gpd.read_file(file_path)\n",
    "gdf = gpd.GeoDataFrame(X_train, geometry=gpd.points_from_xy(X_train['longitude'], X_train['latitude']), crs=cali_shp.crs)\n",
    "gdf.set_crs(cali_shp.crs, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join('CA_Counties', 'CA_Counties_TIGER2016.shp')\n",
    "cali_shp = gpd.read_file(file_path)\n",
    "cali_shp = cali_shp.to_crs(\"EPSG:4326\")\n",
    "gdf = gpd.GeoDataFrame(X_train, geometry=gpd.points_from_xy(X_train['longitude'], X_train['latitude']), crs=cali_shp.crs)\n",
    "gdf = gdf.to_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CityTuple = namedtuple('City', ['Name', 'Latitude', 'Longitude','pop_april_1980', 'pop_april_1990', 'pop_april_2000', 'pop_april_2010'])\n",
    "city_map = dict()\n",
    "for index, row in cal_cities.iterrows():\n",
    "    city_map[row['Name']] = CityTuple(row['Name'], row['Latitude'], row['Longitude'], 0, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in cal_pops_cities.iterrows():\n",
    "    if row['City'] in city_map:\n",
    "        tuple_ = city_map[row['City']]\n",
    "        tuple_ = tuple_._replace(pop_april_1980=row['pop_april_1980'], pop_april_1990=row['pop_april_1990'], pop_april_2000=row['pop_april_2000'], pop_april_2010=row['pop_april_2010'])\n",
    "        city_map[row['City']] = tuple_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_list = [tuple_ for tuple_ in city_map.values()]\n",
    "gdf_cities = gpd.GeoDataFrame(tuple_list, geometry=gpd.points_from_xy([tuple_[2] for tuple_ in tuple_list], [tuple_[1] for tuple_ in tuple_list]), crs=cali_shp.crs)\n",
    "gdf_cities = gdf_cities.to_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_cities[['pop_april_1980','pop_april_1990','pop_april_2000','pop_april_2010']] = gdf_cities[['pop_april_1980','pop_april_1990','pop_april_2000','pop_april_2010']].astype(float)\n",
    "gdf_cities['Large_City'] = gdf_cities['pop_april_2010'] > 250000\n",
    "large_cities = gdf_cities[gdf_cities['Large_City'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_cities_lat_lon = large_cities[['Name','Latitude', 'Longitude']]\n",
    "large_cities_dictionaries = large_cities_lat_lon.to_dict('records', into=OrderedDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for large_city in large_cities_dictionaries:\n",
    "    large_city_base_name = large_city['Name']\n",
    "    large_city_base_name = large_city_base_name.replace(' ', '_').lower()\n",
    "    large_city_enriched_name = large_city_base_name + '_km_distance'\n",
    "    gdf[large_city_enriched_name] = gdf.apply(lambda row: geodesic((row['latitude'], row['longitude']), (large_city['Latitude'], large_city['Longitude'])).kilometers, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_cols = [col for col in gdf.columns if col.endswith('_km_distance')]\n",
    "distance_data = gdf[distance_cols]\n",
    "distance_data.head()    \n",
    "gdf['min_distance'] = distance_data.min(axis=1)\n",
    "gdf['max_distance'] = distance_data.max(axis=1)\n",
    "gdf['min_distance_km_col'] = distance_data.idxmin(axis=1)\n",
    "gdf['max_distance_km_col'] = distance_data.idxmax(axis=1)\n",
    "gdf.drop(columns=distance_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['min_distance_city_name'] = gdf['min_distance_km_col'].apply(lambda x: x.split('_km_distance')[0].replace('_', ' '))\n",
    "gdf.drop(columns=['min_distance_km_col', 'max_distance_km_col', 'max_distance'], inplace=True)\n",
    "gdf.drop(columns=['latitude', 'longitude'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_cities = large_cities.rename(columns={'Name': 'city_name_pops'})\n",
    "large_cities['city_name_pops'] = large_cities['city_name_pops'].apply(lambda x: x.lower())\n",
    "large_cities['city_name_pops'] = large_cities['city_name_pops'].apply(lambda x: x.replace(' ', '_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['min_distance_city_name'] = gdf['min_distance_city_name'].apply(lambda x: x.replace(' ', '_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = gdf.merge(large_cities, how='left', left_on='min_distance_city_name', right_on='city_name_pops')\n",
    "X_train.drop(columns=['city_name_pops', 'Latitude', 'Longitude', 'geometry_y', 'Large_City'], inplace=True)\n",
    "X_train.rename(columns={'geometry_x': 'geometry'}, inplace=True)\n",
    "X_train.drop(columns=['geometry'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[['pop_april_1980', 'pop_april_1990', 'pop_april_2000', 'pop_april_2010']] = X_train[['pop_april_1980', 'pop_april_1990', 'pop_april_2000', 'pop_april_2010']].apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_processor = Pipeline([(\"std_scaler\", StandardScaler())])\n",
    "\n",
    "cat_processor = Pipeline(\n",
    "    [(\"one_hot_encoder\", OneHotEncoder(sparse=False, handle_unknown=\"ignore\"))]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\n",
    "            \"num\",\n",
    "            num_processor,\n",
    "            [\n",
    "                \"housing_median_age\",\n",
    "                \"population\",\n",
    "                \"median_income\",\n",
    "                \"rooms_per_household\",\n",
    "                \"bedrooms_per_room\",\n",
    "                \"population_per_household\",\n",
    "                \"min_distance\",\n",
    "                \"pop_april_1980\",\n",
    "                \"pop_april_1990\",\n",
    "                \"pop_april_2000\",\n",
    "                \"pop_april_2010\",\n",
    "            ],\n",
    "        ),\n",
    "        (\"cat\", cat_processor, [\"min_distance_city_name\", \"ocean_proximity\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [LinearRegression(), DecisionTreeRegressor(), RandomForestRegressor()]:\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('model', model)])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    print(f\"RMSE for {model.__class__.__name__}: {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
